import streamlit as st  # Import the Streamlit library (Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸)
import pandas as pd  # Import the pandas library for data handling (ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸)
from setting_llm import importMyBot

# Set Streamlit page layout to wide (Streamlit í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ ì™€ì´ë“œë¡œ ì„¤ì •)
st.set_page_config(layout="wide")

# Subheader for the page title (í˜ì´ì§€ ì œëª©ì„ ì„œë¸Œí—¤ë”ë¡œ í‘œì‹œ)
st.subheader("ChatBot for EDA and Analytics ğŸ¤–")

# Radio button for selecting dataset (ë°ì´í„° ì„ íƒìš© ë¼ë””ì˜¤ ë²„íŠ¼ êµ¬ì„±)
selectData = st.radio(
    "Select the data you want ChatBot to analyze with EDA.",  # ë¼ë””ì˜¤ ë²„íŠ¼ ì•ˆë‚´ ë¬¸êµ¬
    [
        ":rainbow[Time series data on foreign vessel arrivals at ports across South Korea]",
        ":rainbow[Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan]",
        ":rainbow[Location and address data of the three major ports in Busan]",
        ":rainbow[Monthly and yearly data on the number of ship supplies sales and sales amount]",
        ":rainbow[Meat company data related to shipping supplies]",
        ":rainbow[Food company data related to shipping supplies]",
        ":rainbow[Vacant data around Busan's three major ports]",
        ":rainbow[Time series data on vessel dwell time by shipping company at Busan New Port]",
    ]
)

# Case 1
if selectData == ":rainbow[Time series data on foreign vessel arrivals at ports across South Korea]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Time series data on foreign vessel arrivals at ports across South Korea
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/koreaAllHarbors.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 2
elif selectData == ":rainbow[Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/busanAllPorts_GTCount.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 3
elif selectData == ":rainbow[Location and address data of the three major ports in Busan]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Location and address data of the three major ports in Busan
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/busanThreeport_position.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 4
elif selectData == ":rainbow[Monthly and yearly data on the number of ship supplies sales and sales amount]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Monthly and yearly data on the number of ship supplies sales and sales amount
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/prod_totalCountPrice_yearMonth.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 5
elif selectData == ":rainbow[Meat company data related to shipping supplies]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Meat company data related to shipping supplies
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/company(Meat)_LaLo.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 6
elif selectData == ":rainbow[Food company data related to shipping supplies]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Food company data related to shipping supplies
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/company(Food)_LaLo.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 7
elif selectData == ":rainbow[Vacant data around Busan's three major ports]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Vacant data around Busan's three major ports
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/vacancy_location_LaLo.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()
# Case 8
# elif selectData == ":rainbow[Time series data on vessel dwell time by shipping company at Busan SinHang Port]":
else:
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Time series data on vessel dwell time by shipping company at Busan SinHang Port
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/SinhangSchedule.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()
                
expander = st.expander("Basic LLM Integration Code (using OpenAI API)")
expander.code('''
import os  # Import os module for accessing environment variables (í™˜ê²½ ë³€ìˆ˜ ì ‘ê·¼ì„ ìœ„í•œ os ëª¨ë“ˆ)
import streamlit as st  # Import Streamlit for interactive web interface (ëŒ€í™”í˜• ì›¹ ì¸í„°í˜ì´ìŠ¤ ì œê³µì„ ìœ„í•œ Streamlit ì„í¬íŠ¸)
import matplotlib.pyplot as plt  # Import matplotlib (used for plotting) (ì‹œê°í™”ë¥¼ ìœ„í•œ matplotlib ì„í¬íŠ¸)
import matplotlib.font_manager as fm  # Font manager for matplotlib (matplotlib í°íŠ¸ ë§¤ë‹ˆì € ì„í¬íŠ¸)
from dotenv import load_dotenv  # Load environment variables from a .env file (.env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°)
from langchain_openai import ChatOpenAI  # OpenAI LLM interface via LangChain (LangChain ê¸°ë°˜ OpenAI ì–¸ì–´ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤)
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent  # LangChain agent for DataFrame (Pandas ë°ì´í„°í”„ë ˆì„ ë¶„ì„ìš© LangChain ì—ì´ì „íŠ¸)
from langchain_core.prompts import ChatPromptTemplate  # Role-based prompt template generator (ì—­í•  ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±)
from langchain_core.output_parsers import StrOutputParser  # Simple string output parser (ë‹¨ìˆœ ë¬¸ìì—´ ë°˜í™˜ íŒŒì„œ)

# Set font for Korean display in matplotlib (matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •)
plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows ê¸°ì¤€ ë§êµ¿ ê³ ë”• ì ìš©
plt.rcParams['axes.unicode_minus'] = False  # Prevent broken minus sign (ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê¹¨ì§ ë°©ì§€)

# Main chatbot function that processes user questions, runs LLM + EDA + Visualization
# (LLM + ë°ì´í„°í”„ë ˆì„ ë¶„ì„ + ì‹œê°í™”ë¥¼ í†µí•©í•œ ë©”ì¸ ì±—ë´‡ í•¨ìˆ˜)
def importMyBot(x, userQuestion):
    """
    Parameters:
    x : pd.DataFrame - DataFrame to analyze (ë¶„ì„í•  ë°ì´í„°í”„ë ˆì„)
    userQuestion : str - User question or command (ì‚¬ìš©ì ì§ˆë¬¸ ë˜ëŠ” ëª…ë ¹)

    Returns:
    str or None - Textual response or None if image is returned (í…ìŠ¤íŠ¸ ì‘ë‹µ ë˜ëŠ” ì´ë¯¸ì§€ ë°˜í™˜ì‹œ None)
    """

    # Load API key from .env (í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ë¡œë“œ)
    load_dotenv()
    OPENAI_API_KEY = os.getenv("openAI_myKey")

    # Initialize LLM with gpt-4o-mini for cost-effective inference (gpt-4o-mini ëª¨ë¸ ì´ˆê¸°í™”)
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=1,
        api_key=OPENAI_API_KEY
    )

    # Create chatbot personality and behavior prompt (ì±—ë´‡ ìºë¦­í„° ì„¤ì • ë° ì‘ë‹µ ê·œì¹™ ì •ì˜)
    prompt = ChatPromptTemplate.from_messages([
        {
            "role": "system",
            "content": '''
            From now on, your name is Javis. You worked for the genius hero Iron Man Tony Stark and came to me after being hired.
            Your job is to answer based on the user's tone, in their language, with integrity and precision.

            Rules:
            1. If you are asked a question in English, answer in English.
            2. If you are asked a question in Korean, answer in Korean.
            3. You must only provide aggregated and factual information about the data you have, and absolutely must not provide false information.
            4. When expressing it numerically, only say the number.
            5. If the user has questions that are not related to the data you have, guide them to use Google Search.
            6. When the user asks about the data, talk about it based on basic EDA.
            '''
        },
        {"role": "user", "content": "{input}"}
    ])

    # Combine prompt â†’ LLM â†’ output parser into a chain (í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ íŒŒì„œ ì²´ì¸ êµ¬ì„±)
    output_parser = StrOutputParser()
    myChain = prompt | llm | output_parser

    # Create a LangChain agent that can interact with the DataFrame using natural language
    # (ìì—°ì–´ë¥¼ ì´ìš©í•´ ë°ì´í„°í”„ë ˆì„ê³¼ ìƒí˜¸ì‘ìš©í•˜ëŠ” LangChain ì—ì´ì „íŠ¸ êµ¬ì„±)
    agent_data_executer = create_pandas_dataframe_agent(
        llm=llm,
        df=x,
        agent_type="tool-calling",
        verbose=True,
        return_intermediate_steps=True,
        allow_dangerous_code=True
    )

    # List of keywords to detect if the user is asking for visualization (ì‹œê°í™” ìš”ì²­ í‚¤ì›Œë“œ ì •ì˜)
    visualization_keywords = [
        # English (ì˜ì–´)
        "plot", "graph", "chart", "visualize", "display", "show", "draw", "render",
        "hist", "bar", "line", "scatter", "pie", "map", "heatmap", "box", "area",
        "bubble", "density", "distribution", "trend", "time series", "stacked", "plotly",
        "matplotlib", "seaborn", "bokeh", "dash", "altair", "gantt", "treemap", "sunburst",

        # Korean (í•œê¸€)
        "ì‹œê°í™”", "ê·¸ë˜í”„", "íˆìŠ¤í† ê·¸ë¨", "ë§‰ëŒ€ê·¸ë˜í”„", "ì‚°ì ë„", "íŒŒì´ì°¨íŠ¸", "ì„ í˜•ê·¸ë˜í”„", "ë¶„í¬ë„", "ìƒìê·¸ë¦¼",
        "ì§€ë„", "ì—´ì§€ë„", "ë°€ë„ì°¨íŠ¸", "íŠ¸ë Œë“œ", "ì‹œê³„ì—´", "ëˆ„ì ê·¸ë˜í”„", "êµ°ì§‘ë„", "íŠ¸ë¦¬ë§µ", "ì„ ë²„ìŠ¤íŠ¸", "ë¹„ì˜¬ë¦°í”Œë¡¯"
    ]

    # Case 1: Visualization requested (ì‹œê°í™” ìš”ì²­ ì‹œ)
    if any(kw in userQuestion.lower() for kw in visualization_keywords):
        response = agent_data_executer.invoke(userQuestion)  # ì—ì´ì „íŠ¸ ì‹¤í–‰
        try:
            visual_code = response["intermediate_steps"][0][0].tool_input["query"]  # ìƒì„±ëœ ì½”ë“œ ì¶”ì¶œ
            df = x.copy()  # ì½”ë“œ ë‚´ì—ì„œ ì‚¬ìš©ë  df ì •ì˜

            exec(visual_code)  # ì‹œê°í™” ì½”ë“œ ì‹¤í–‰

            # ì‹œê°í™” ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥
            import io
            buf = io.BytesIO()
            plt.savefig(buf, format="png")
            buf.seek(0)

            # ì´ë¯¸ì§€ ë²„í¼ë¥¼ ì„¸ì…˜ì— ì €ì¥í•˜ì—¬ Streamlitì—ì„œ ë Œë”ë§
            st.session_state.messages.append({
                "role": "ai",
                "type": "image",
                "content": buf
            })

            return None  # ì‹œê°í™”ëŠ” í…ìŠ¤íŠ¸ ì‘ë‹µ ì—†ì´ ì¢…ë£Œ

        except Exception as e:
            return f"Error while executing visualization: {e}"  # ì—ëŸ¬ í•¸ë“¤ë§

    # Case 2: Data-related summary/EDA questions (EDA ì§ˆë¬¸ì¼ ê²½ìš°)
    elif any(kw in userQuestion.lower() for kw in [
        "data", "column", "row", "mean", "sum", "describe", "ë°ì´í„°", "ì»¬ëŸ¼", "í–‰", "ì—´", "ìš”ì•½", "í‰ê· ", "EDA"
    ]):
        result = agent_data_executer.invoke(userQuestion)  # ì—ì´ì „íŠ¸ ì‹¤í–‰
        return result["output"]  # ê²°ê³¼ í…ìŠ¤íŠ¸ ë°˜í™˜

    # Case 3: General character conversation (ì¼ë°˜ ìºë¦­í„° ì‘ë‹µ)
    else:
        result = myChain.invoke({"input": userQuestion})  # ì¼ë°˜ ì±—ë´‡ ì‘ë‹µ
        return result  # í…ìŠ¤íŠ¸ ë°˜í™˜

import streamlit as st  # Import the Streamlit library (Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸)
import pandas as pd  # Import the pandas library for data handling (ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸)
from setting_llm import importMyBot  # Import custom chatbot logic (ì‚¬ìš©ì ì •ì˜ ì±—ë´‡ ë¡œì§ ì„í¬íŠ¸)

# Set Streamlit page layout to wide format (Streamlit í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ ì™€ì´ë“œ í¬ë§·ìœ¼ë¡œ ì„¤ì •)
st.set_page_config(layout="wide")

# Display a subheader as the chatbot title (ì±—ë´‡ ì œëª©ì„ ì„œë¸Œí—¤ë”ë¡œ í‘œì‹œ)
st.subheader("ChatBot for EDA and Analytics")

# Define dataset selection radio buttons (ë¶„ì„í•  ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ê¸° ìœ„í•œ ë¼ë””ì˜¤ ë²„íŠ¼ ì •ì˜)
selectData = st.radio(
    "Select the data you want ChatBot to analyze with EDA.",  # Instruction for dataset selection (ë°ì´í„°ì…‹ ì„ íƒì„ ìœ„í•œ ì•ˆë‚´ ë¬¸êµ¬)
    [
        ":rainbow[Time series data on foreign vessel arrivals at ports across South Korea]",
        ":rainbow[Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan]",
        ":rainbow[Location and address data of the three major ports in Busan]",
        ":rainbow[Monthly and yearly data on the number of ship supplies sales and sales amount]",
        ":rainbow[Meat company data related to shipping supplies]",
        ":rainbow[Food company data related to shipping supplies]",
        ":rainbow[Vacant data around Busan's three major ports]",
        ":rainbow[Time series data on vessel dwell time by shipping company at Busan New Port]",
    ]
)

# Dictionary mapping each selection to its corresponding CSV file (ì„ íƒí•œ ì˜µì…˜ì— ë”°ë¥¸ CSV íŒŒì¼ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬)
data_sources = {
    ":rainbow[Time series data on foreign vessel arrivals at ports across South Korea]": "./useData/forLLM_data/koreaAllHarbors.csv",
    ":rainbow[Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan]": "./useData/forLLM_data/busanAllPorts_GTCount.csv",
    ":rainbow[Location and address data of the three major ports in Busan]": "./useData/forLLM_data/busanThreeport_position.csv",
    ":rainbow[Monthly and yearly data on the number of ship supplies sales and sales amount]": "./useData/forLLM_data/prod_totalCountPrice_yearMonth.csv",
    ":rainbow[Meat company data related to shipping supplies]": "./useData/forLLM_data/company(Meat)_LaLo.csv",
    ":rainbow[Food company data related to shipping supplies]": "./useData/forLLM_data/company(Food)_LaLo.csv",
    ":rainbow[Vacant data around Busan's three major ports]": "./useData/forLLM_data/vacancy_location_LaLo.csv",
    ":rainbow[Time series data on vessel dwell time by shipping company at Busan New Port]": "./useData/forLLM_data/SinhangSchedule.csv",
}

# Display header indicating current selection (í˜„ì¬ ì„ íƒëœ ë°ì´í„°ì…‹ì„ ê°•ì¡°í•˜ëŠ” í—¤ë” í‘œì‹œ)
st.markdown(
    f"""
    <div style='background-color:#cce5ff; padding:10px; border-radius:5px;'>
        <span style='color:#ff8c00; font-weight:bold;'>
            ğŸ“Œ Currently selected data: <br> {selectData.split(']')[1]}
        </span>
    </div>
    """, unsafe_allow_html=True
)

# Layout with two columns for data and chatbot (ë°ì´í„°ì™€ ì±—ë´‡ UIë¥¼ ìœ„í•œ 2ì—´ ë ˆì´ì•„ì›ƒ êµ¬ì„±)
dataArea, chatBotArea = st.columns(2)

# Load and show selected data in the left column (ì„ íƒí•œ ë°ì´í„°ë¥¼ ì¢Œì¸¡ ì˜ì—­ì— í‘œì‹œ)
with dataArea:
    with st.container(height=450):  # Set a fixed height container (ê³ ì • ë†’ì´ ì»¨í…Œì´ë„ˆ ì„¤ì •)
        readData = pd.read_csv(data_sources[selectData], encoding="utf-8-sig")
        st.dataframe(readData, use_container_width=True, hide_index=True)  # Show data table (ë°ì´í„° í…Œì´ë¸” í‘œì‹œ)

# Chat interface area in the right column (ìš°ì¸¡ì— ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì˜ì—­ êµ¬ì„±)
with chatBotArea:
    with st.container(height=450):

        # Initialize message session state if not already created (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # If no previous chat, show welcome image (ëŒ€í™” ì´ë ¥ì´ ì—†ìœ¼ë©´ í™˜ì˜ ì´ë¯¸ì§€ í‘œì‹œ)
        if len(st.session_state.messages) == 0:
            with st.container(height=350):
                st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)
        else:
            with st.container(height=350):
                # Display past chat messages (ì´ì „ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ)
                for message in st.session_state.messages:
                    with st.chat_message(message["role"]):
                        if message.get("type") == "image":
                            st.image(
                                message["content"],
                                caption="Generated Visualization",  # Image caption (ì´ë¯¸ì§€ ìº¡ì…˜)
                                use_container_width=True
                            )
                        else:
                            st.markdown(message["content"])  # Display text as markdown (ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ í‘œì‹œ)

        # Input field for user message (ì‚¬ìš©ì ë©”ì‹œì§€ ì…ë ¥ í•„ë“œ)
        userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")

        if userStart:
            st.session_state.messages.append({"role": "user", "content": userStart})  # Save user message (ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥)

            systemAnswer = importMyBot(readData, userStart)  # Get chatbot reply (ì±—ë´‡ ì‘ë‹µ ë°›ê¸°)

            if systemAnswer:
                st.session_state.messages.append({"role": "ai", "content": systemAnswer})  # Save chatbot reply (ì±—ë´‡ ë©”ì‹œì§€ ì €ì¥)

            st.rerun()  # Rerun UI to update messages (UI ì¬ì‹¤í–‰í•˜ì—¬ ë©”ì‹œì§€ ê°±ì‹ )

''')
