import streamlit as st  # Import the Streamlit library (Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸)
import pandas as pd  # Import the pandas library for data handling (ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸)
from setting_llm import importMyBot

# Set Streamlit page layout to wide (Streamlit í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ ì™€ì´ë“œë¡œ ì„¤ì •)
st.set_page_config(layout="wide")

# Subheader for the page title (í˜ì´ì§€ ì œëª©ì„ ì„œë¸Œí—¤ë”ë¡œ í‘œì‹œ)
st.subheader("ChatBot for EDA and Analytics ğŸ¤–")

# Radio button for selecting dataset (ë°ì´í„° ì„ íƒìš© ë¼ë””ì˜¤ ë²„íŠ¼ êµ¬ì„±)
selectData = st.radio(
    "Select the data you want ChatBot to analyze with EDA.",  # ë¼ë””ì˜¤ ë²„íŠ¼ ì•ˆë‚´ ë¬¸êµ¬
    [
        ":rainbow[Time series data on foreign vessel arrivals at ports across South Korea]",
        ":rainbow[Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan]",
        ":rainbow[Location and address data of the three major ports in Busan]",
        ":rainbow[Monthly and yearly data on the number of ship supplies sales and sales amount]",
        ":rainbow[Meat company data related to shipping supplies]",
        ":rainbow[Food company data related to shipping supplies]",
        ":rainbow[Vacant data around Busan's three major ports]",
        ":rainbow[Time series data on vessel dwell time by shipping company at Busan New Port]",
    ]
)

# Case 1
if selectData == ":rainbow[Time series data on foreign vessel arrivals at ports across South Korea]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Time series data on foreign vessel arrivals at ports across South Korea
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/koreaAllHarbors.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 2
elif selectData == ":rainbow[Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/busanAllPorts_GTCount.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 3
elif selectData == ":rainbow[Location and address data of the three major ports in Busan]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Location and address data of the three major ports in Busan
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/busanThreeport_position.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 4
elif selectData == ":rainbow[Monthly and yearly data on the number of ship supplies sales and sales amount]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Monthly and yearly data on the number of ship supplies sales and sales amount
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/prod_totalCountPrice_yearMonth.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 5
elif selectData == ":rainbow[Meat company data related to shipping supplies]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Meat company data related to shipping supplies
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/company(Meat)_LaLo.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 6
elif selectData == ":rainbow[Food company data related to shipping supplies]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Food company data related to shipping supplies
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/company(Food)_LaLo.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()

# Case 7
elif selectData == ":rainbow[Vacant data around Busan's three major ports]":
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Vacant data around Busan's three major ports
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/vacancy_location_LaLo.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()
# Case 8
# elif selectData == ":rainbow[Time series data on vessel dwell time by shipping company at Busan SinHang Port]":
else:
    st.markdown(
        """
        <div style="background-color:#cce5ff; padding:10px; border-radius:5px;">
            <span style="color:#ff8c00; font-weight:bold;">
                ğŸ“Œ Currently selected data:
                Time series data on vessel dwell time by shipping company at Busan SinHang Port
            </span>
        </div>
        """, unsafe_allow_html=True
    )

    dataArea, chatBotArea = st.columns(2)

    with dataArea:
        with st.container(height=450):
            readData = pd.read_csv("./useData/forLLM_data/SinhangSchedule.csv", encoding="utf-8-sig")
            st.dataframe(readData, use_container_width=True, hide_index=True)

    with chatBotArea:
        # Main container for the chatbot interface (ì±„íŒ… UIë¥¼ ë‹´ëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆ)
        with st.container(height=450):

            # Initialize message history in session state if not already present
            # (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
            if "messages" not in st.session_state:
                st.session_state.messages = []

            # If there are no previous messages, show a welcome image
            # (ëŒ€í™” ë‚´ì—­ì´ ì—†ëŠ” ê²½ìš°, ì²« í™”ë©´ì— í™˜ì˜ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ)
            if len(st.session_state.messages) == 0:
                with st.container(height=350):
                    st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)

            else:
                # If there are messages, render them inside a container
                # (ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´, ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë Œë”ë§)
                with st.container(height=350):
                    for message in st.session_state.messages:
                        if message.get("type") == "image":
                            # If the message is of type 'image', render it in chat bubble
                            # (ë©”ì‹œì§€ íƒ€ì…ì´ ì´ë¯¸ì§€ì´ë©´, ì±„íŒ… ë§í’ì„  ì•ˆì— ì´ë¯¸ì§€ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.image(
                                    message["content"],
                                    caption="Generated Visualization",  # Caption under the image (ì´ë¯¸ì§€ í•˜ë‹¨ ìº¡ì…˜)
                                    use_container_width=True  # Fit image to container width (ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤)
                                )
                        else:
                            # Otherwise, render text content in chat bubble
                            # (í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì¼ë°˜ ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ)
                            with st.chat_message(message["role"]):
                                st.markdown(message["content"])  # Render message text as markdown (ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì¶œë ¥)

            # Chat input box at the bottom of the screen
            # (í•˜ë‹¨ì— ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±)
            userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")
            if userStart:
                # Append user's message to session state history
                # (ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë©”ì‹œì§€ ê¸°ë¡ì— ì¶”ê°€)
                st.session_state.messages.append({"role": "user", "content": userStart})

                # Run the custom chatbot logic and get the system's response
                # (ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë´‡ í•¨ìˆ˜ ì‹¤í–‰ í›„ ì‘ë‹µ ìˆ˜ì‹ )
                systemAnswer = importMyBot(readData, userStart)

                # If there's a valid response, add it to the chat
                # (ìœ íš¨í•œ ì‘ë‹µì´ ìˆì„ ê²½ìš°, ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€)
                if systemAnswer:
                    st.session_state.messages.append({"role": "ai", "content": systemAnswer})

                # Force UI to rerun so the new messages render immediately
                # (UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¦‰ì‹œ ë°˜ì˜)
                st.rerun()
                
expander = st.expander("Basic LLM Integration Code (using OpenAI API)")
expander.code('''
import streamlit as st  # Import the Streamlit library (Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸)
import pandas as pd  # Import the pandas library for data handling (ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸)
from setting_llm import importMyBot  # Import custom chatbot logic (ì‚¬ìš©ì ì •ì˜ ì±—ë´‡ ë¡œì§ ì„í¬íŠ¸)

# Set Streamlit page layout to wide format (Streamlit í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ ì™€ì´ë“œ í¬ë§·ìœ¼ë¡œ ì„¤ì •)
st.set_page_config(layout="wide")

# Display a subheader as the chatbot title (ì±—ë´‡ ì œëª©ì„ ì„œë¸Œí—¤ë”ë¡œ í‘œì‹œ)
st.subheader("ChatBot for EDA and Analytics")

# Define dataset selection radio buttons (ë¶„ì„í•  ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ê¸° ìœ„í•œ ë¼ë””ì˜¤ ë²„íŠ¼ ì •ì˜)
selectData = st.radio(
    "Select the data you want ChatBot to analyze with EDA.",  # Instruction for dataset selection (ë°ì´í„°ì…‹ ì„ íƒì„ ìœ„í•œ ì•ˆë‚´ ë¬¸êµ¬)
    [
        ":rainbow[Time series data on foreign vessel arrivals at ports across South Korea]",
        ":rainbow[Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan]",
        ":rainbow[Location and address data of the three major ports in Busan]",
        ":rainbow[Monthly and yearly data on the number of ship supplies sales and sales amount]",
        ":rainbow[Meat company data related to shipping supplies]",
        ":rainbow[Food company data related to shipping supplies]",
        ":rainbow[Vacant data around Busan's three major ports]",
        ":rainbow[Time series data on vessel dwell time by shipping company at Busan New Port]",
    ]
)

# Dictionary mapping each selection to its corresponding CSV file (ì„ íƒí•œ ì˜µì…˜ì— ë”°ë¥¸ CSV íŒŒì¼ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬)
data_sources = {
    ":rainbow[Time series data on foreign vessel arrivals at ports across South Korea]": "./useData/forLLM_data/koreaAllHarbors.csv",
    ":rainbow[Time series data on the number of vessel arrivals and cargo throughput at the three major ports in Busan]": "./useData/forLLM_data/busanAllPorts_GTCount.csv",
    ":rainbow[Location and address data of the three major ports in Busan]": "./useData/forLLM_data/busanThreeport_position.csv",
    ":rainbow[Monthly and yearly data on the number of ship supplies sales and sales amount]": "./useData/forLLM_data/prod_totalCountPrice_yearMonth.csv",
    ":rainbow[Meat company data related to shipping supplies]": "./useData/forLLM_data/company(Meat)_LaLo.csv",
    ":rainbow[Food company data related to shipping supplies]": "./useData/forLLM_data/company(Food)_LaLo.csv",
    ":rainbow[Vacant data around Busan's three major ports]": "./useData/forLLM_data/vacancy_location_LaLo.csv",
    ":rainbow[Time series data on vessel dwell time by shipping company at Busan New Port]": "./useData/forLLM_data/SinhangSchedule.csv",
}

# Display header indicating current selection (í˜„ì¬ ì„ íƒëœ ë°ì´í„°ì…‹ì„ ê°•ì¡°í•˜ëŠ” í—¤ë” í‘œì‹œ)
st.markdown(
    f"""
    <div style='background-color:#cce5ff; padding:10px; border-radius:5px;'>
        <span style='color:#ff8c00; font-weight:bold;'>
            ğŸ“Œ Currently selected data: <br> {selectData.split(']')[1]}
        </span>
    </div>
    """, unsafe_allow_html=True
)

# Layout with two columns for data and chatbot (ë°ì´í„°ì™€ ì±—ë´‡ UIë¥¼ ìœ„í•œ 2ì—´ ë ˆì´ì•„ì›ƒ êµ¬ì„±)
dataArea, chatBotArea = st.columns(2)

# Load and show selected data in the left column (ì„ íƒí•œ ë°ì´í„°ë¥¼ ì¢Œì¸¡ ì˜ì—­ì— í‘œì‹œ)
with dataArea:
    with st.container(height=450):  # Set a fixed height container (ê³ ì • ë†’ì´ ì»¨í…Œì´ë„ˆ ì„¤ì •)
        readData = pd.read_csv(data_sources[selectData], encoding="utf-8-sig")
        st.dataframe(readData, use_container_width=True, hide_index=True)  # Show data table (ë°ì´í„° í…Œì´ë¸” í‘œì‹œ)

# Chat interface area in the right column (ìš°ì¸¡ì— ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì˜ì—­ êµ¬ì„±)
with chatBotArea:
    with st.container(height=450):

        # Initialize message session state if not already created (ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”)
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # If no previous chat, show welcome image (ëŒ€í™” ì´ë ¥ì´ ì—†ìœ¼ë©´ í™˜ì˜ ì´ë¯¸ì§€ í‘œì‹œ)
        if len(st.session_state.messages) == 0:
            with st.container(height=350):
                st.image("./useImage/gptReady.png")  # Welcome image (í™˜ì˜ ì´ë¯¸ì§€)
        else:
            with st.container(height=350):
                # Display past chat messages (ì´ì „ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ)
                for message in st.session_state.messages:
                    with st.chat_message(message["role"]):
                        if message.get("type") == "image":
                            st.image(
                                message["content"],
                                caption="Generated Visualization",  # Image caption (ì´ë¯¸ì§€ ìº¡ì…˜)
                                use_container_width=True
                            )
                        else:
                            st.markdown(message["content"])  # Display text as markdown (ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ í‘œì‹œ)

        # Input field for user message (ì‚¬ìš©ì ë©”ì‹œì§€ ì…ë ¥ í•„ë“œ)
        userStart = st.chat_input("Ask questions you're curious about, but don't type illegal or violent words.")

        if userStart:
            st.session_state.messages.append({"role": "user", "content": userStart})  # Save user message (ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥)

            systemAnswer = importMyBot(readData, userStart)  # Get chatbot reply (ì±—ë´‡ ì‘ë‹µ ë°›ê¸°)

            if systemAnswer:
                st.session_state.messages.append({"role": "ai", "content": systemAnswer})  # Save chatbot reply (ì±—ë´‡ ë©”ì‹œì§€ ì €ì¥)

            st.rerun()  # Rerun UI to update messages (UI ì¬ì‹¤í–‰í•˜ì—¬ ë©”ì‹œì§€ ê°±ì‹ )

''')
expander.image("ht
